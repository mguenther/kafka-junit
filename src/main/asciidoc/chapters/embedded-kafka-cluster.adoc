[[section:embedded-kafka-cluster]]

== Working with an embedded Kafka cluster

Kafka for JUnit is able to spin up a fully-fledged embedded Kafka cluster that is accessible via class `EmbeddedKafkaCluster`. `EmbeddedKafkaCluster` implements the interfaces `RecordProducer`, `RecordConsumer` and `TopicManager` and thus provides convenient accessors to interact with the cluster.

Using `EmbeddedKafkaCluster` in a JUnit test is quite simple. The necessary code to set it up is minimal if you are comfortable with the default configuration.

[source,java]
----
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;

import static net.mguenther.kafka.junit.EmbeddedKafkaCluster.provisionWith;
import static net.mguenther.kafka.junit.EmbeddedKafkaClusterConfig.defaultClusterConfig;

class KafkaTest {

    private EmbeddedKafkaCluster kafka;

    @BeforeEach
    void setupKafka() {
        kafka = provisionWith(defaultClusterConfig());
        kafka.start();
    }

    @AfterEach
    void tearDownKafka() {
        kafka.stop();
    }
}
----

Kafka for JUnit uses the Builder pattern extensively to provide a fluent API when provisioning an embedded Kafka cluster. Let's take a closer look at method `EmbeddedKafkaCluster.provisionWith`. This method consumes a configuration of type `EmbeddedKafkaClusterConfig`. `EmbeddedKafkaClusterConfig` uses defaults for the Kafka broker and ZooKeeper. By default, Kafka Connect will not be provisioned at all. The builder of `EmbeddedKafkaClusterConfig` provides a `provisionWith` method as well and is overloaded to accept configurations of type `EmbeddedZooKeeperConfig`, `EmbeddedKafkaConfig` and `EmbeddedConnectConfig`. The following listing demonstrates how to adjust the configuration of the embedded Kafka broker wrt. the default number of partitions for newly created topics.

[source,java]
----
EmbeddedKafkaCluster kafka = provisionWith(newClusterConfig()
    .configure(kafkaConnect()
    .with(KafkaConfig$.MODULE$.NumPartitionsProp(), "5")));
----

The builders for those configurations provide a uniform interface for overriding defaults, comprising two methods `with(String propertyName, T value)` and `withAll(java.util.Properties overrides)`. To override a default value, you simply provide the name of the configuration parameter as defined by the resp. Kafka component along with the new value.

Using the default setting will provide you with a single embedded Kafka broker. This ought to be sufficient for most cases. However, there are scenarios which require testing against multiple brokers that form a cluster. Forming an embedded cluster with multiple brokers is done by adjusting the default provisioning of your test case. See the listing underneath for an example.

[source,java]
----

EmbeddedKafkaCluster kafka = provisionWith(newClusterConfig()
    .configure(brokers()
        .withNumberOfBrokers(3)
        .with(KafkaConfig$.MODULE$.NumPartitionsProp(), "5")
        .with(KafkaConfig$.MODULE$.DefaultReplicationFactorProp(), "3")
        .with(KafkaConfig$.MODULE$.MinInSyncReplicasProp(), "2")
        .with(KafkaConfig$.MODULE$.OffsetsTopicReplicationFactorProp(), "3")
        .with(KafkaConfig$.MODULE$.TransactionsTopicReplicationFactorProp(), "3")
        .with(KafkaConfig$.MODULE$.TransactionsTopicMinISRProp(), "2")));
----

Using this configuration, we end up with a total of three brokers that form an embedded Kafka cluster, while the defaults for topic partitions and replicas have been adjusted to be consistent with the size of the cluster.

Of course, you can also use the `try-with-resources`-pattern to fire up an embedded cluster. Have a look at the following test setup.

[source,java]
----
import org.junit.jupiter.api.Test;

import static net.mguenther.kafka.junit.EmbeddedKafkaCluster.provisionWith;
import static net.mguenther.kafka.junit.EmbeddedKafkaClusterConfig.defaultClusterConfig;

class KafkaTest {

  @Test
  void shouldWaitForRecordsToBePublished() throws Exception {

    try (EmbeddedKafkaCluster kafka = provisionWith(defaultClusterConfig())) {
      kafka.start();
      kafka.send(to("test-topic", "a", "b", "c"));
      kafka.observe(on("test-topic", 3));
    }
  }
}
----

See sections on <<section:producing-records, Producing records>>, <<section:consuming-records, Consuming records>> and <<section:managing-topics, Managing topics>> for further reference on how to interact with the cluster.

=== Failure Modes

`EmbeddedKafkaCluster` provides the means to disconnect - and re-connect of course - specific embedded Kafka brokers. All brokers in the embedded cluster get broker ID assigned during cluster formation. This broker ID is an `Integer`-based value and starts at 1. The broker ID increases by 1 for every subsequent embedded Kafka broker that is started during cluster formation.

Clusters stay fixed wrt. the maximum number of embedded brokers. But individual brokers can, given their broker ID, be disconnected from the rest of the cluster to test for failure scenarios. Such failure scenarios include:

* How does may Kafka-based component behave in the presence of broker outages?
* What happens if the In-Sync-Replica Set (ISR) of a topic that my application consumes from shrinks below its minimum size?
* Is my application able to progress after brokers re-connect and form a working cluster?

==== Disconnect and reconnect a single broker

The following listing shows how to disconnect and re-connect a certain broker, while fetching the ISR of a dedicated topic in between these operations to determine whether the cluster behaves correctly.

NOTE: If you do use this feature of Kafka for JUnit, then please give the embedded cluster some time to handle broker churn. Identifying that a leader for a topic-partition is not available and conducting the leader election takes some time. In the example underneath we introduce a delay of five seconds in between operations that affect cluster membership.

[source,java]
----
kafka.createTopic(TopicConfig.withName("test-topic")
    .withNumberOfPartitions(5)
    .withNumberOfReplicas(3));

delay(5);

Set<Integer> leaders = kafka.fetchLeaderAndIsr("test-topic")
    .values()
    .stream()
    .map(LeaderAndIsr::getLeader)
    .collect(Collectors.toSet());

assertThat(leaders.contains(1)).isTrue();
assertThat(leaders.contains(2)).isTrue();
assertThat(leaders.contains(3)).isTrue();

kafka.disconnect(1);

delay(5);

Set<Integer> leadersAfterDisconnect = kafka.fetchLeaderAndIsr("test-topic")
    .values()
    .stream()
    .map(LeaderAndIsr::getLeader)
    .collect(Collectors.toSet());

assertThat(leadersAfterDisconnect.contains(1)).isFalse();
assertThat(leadersAfterDisconnect.contains(2)).isTrue();
assertThat(leadersAfterDisconnect.contains(3)).isTrue();

kafka.connect(1);

delay(5);

Set<Integer> leadersAfterReconnect = kafka.fetchLeaderAndIsr("test-topic")
    .values()
    .stream()
    .map(LeaderAndIsr::getLeader)
    .collect(Collectors.toSet());

assertThat(leadersAfterReconnect.contains(1)).isTrue();
assertThat(leadersAfterReconnect.contains(2)).isTrue();
assertThat(leadersAfterReconnect.contains(3)).isTrue();
----

==== Disconnect until In-Sync-Replica Set falls below minimum size

The following listing shows how to disconnect the In-Sync-Replica Set (ISR) for a given topic until its ISR falls below its minimum size.

NOTE: If you do use this feature of Kafka for JUnit, then please give the embedded cluster some time to handle broker churn. Identifying that a leader for a topic-partition is not available and conducting the leader election takes some time. In the example underneath we introduce a delay of five seconds in between operations that affect cluster membership.

[source,java]
----
// Create a topic and configure the number of replicas as well as the size of the ISR

kafka.createTopic(TopicConfig.withName("test-topic")
    .withNumberOfPartitions(5)
    .withNumberOfReplicas(3)
    .with("min.insync.replicas", "2"));

// Wait a bit to give the cluster a chance to properly assign topic-partitions to leaders

delay(5);

// Disconnect until the remaining number of brokers fall below the minimum ISR size

kafka.disconnectUntilIsrFallsBelowMinimumSize("test-topic");

delay(5);

// Submitting records to this topic will yield a NotEnoughReplicasException

kafka.send(SendValues.to("test-topic", "A"));
----

The last line of the listing shows the effect of an ISR that can no longer operate reliably. Your Kafka-based component or application would run concurrently to this test so that you are able to observe if it behaves correctly (e.g. by checking that the component progresses normally if the ISR is restored).

==== Restoring the In-Sync-Replica Set

Restoring the In-Sync-Replica Set is easy, as method `disconnectUntilIsrFallsBelowMinimumSize` returns a list of broker IDs for all brokers that have been deactivated during the shrinking. The following listing shows how to restore the ISR.

[source,java]
----
kafka.createTopic(TopicConfig.withName("test-topic")
    .withNumberOfPartitions(5)
    .withNumberOfReplicas(3)
    .with("min.insync.replicas", "2"));

delay(5);

Set<Integer> disconnectedBrokers = kafka.disconnectUntilIsrFallsBelowMinimumSize("test-topic");

delay(5);

// Do some testing, trigger some operations, observe the behavior of your application

kafka.connect(disconnectedBrokers);

// Give the cluster some time to assign leaders and reestablish the ISR

delay(5);

// Do some more testing ...
----